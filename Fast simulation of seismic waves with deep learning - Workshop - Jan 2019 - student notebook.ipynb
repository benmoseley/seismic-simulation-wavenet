{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast approximate simulation of seismic waves with deep learning\n",
    "\n",
    "# Machine learning workshop - student notebook\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Author: Ben Moseley, Centre for Autonomous Intelligent Machines and Systems, University of Oxford, bmoseley@robots.ox.ac.uk \n",
    "\n",
    "This workshop reproduces the results of the paper: *[Fast approximate simulation of seismic waves with deep learning](https://arxiv.org/abs/1807.06873), NeurIPS 2018, B. Moseley, A. Markham and T. Nissen-Meyer*.\n",
    "\n",
    "Last updated: Jan 2019\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"figures/header.png\" width=\"600\">\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Seismic simulation** is crucial for many geophysical applications, yet traditional approaches are **computationally expensive**.\n",
    "\n",
    "- In this workshop, we will use **deep learning** to simulate seismic waves.\n",
    "\n",
    "- We will show that this can offer a **fast approximate alternative** to traditional simulation methods.\n",
    "\n",
    "---\n",
    "\n",
    "This workshop takes ~ 1-2 hrs to complete. All the code for this notebook can be found here: https://github.com/benmoseley/seismic-simulation-wavenet\n",
    "\n",
    "---\n",
    "\n",
    "## Task\n",
    "\n",
    "For this proof of principle study, we will consider the simulation of **acoustic waves** propagating in synthetic **horizontally layered** media.\n",
    "\n",
    "Specifically, we will consider a single fixed point source propagating through a horizonally layered velocity model with 11 fixed receivers horizontally offset from the source, shown below.\n",
    "\n",
    "<img src=\"figures/example_simulation.png\" width=\"600\"><!---include \"\" for proper github rendering-->\n",
    "\n",
    "Left: input velocity model, triangles show receiver locations. Right: wavefield pressure after 1 s, using acoustic Finite-Difference (FD) modelling,  black circle shows fixed point source location.\n",
    "\n",
    "Our task is as follows:\n",
    "\n",
    "> Given a randomly selected layered velocity model as input, can we train a neural network to simulate the pressure response recorded at each receiver location?\n",
    "\n",
    "We wish our neural network to generalise well to velocity models unseen during training. We will compare our results to traditional FD modelling.\n",
    "\n",
    "\n",
    "## Workflow\n",
    "\n",
    "We will use the following workflow to complete this task;\n",
    "\n",
    "- we will preprocess the input velocity profile into its corresponding reflectivity series;\n",
    "\n",
    "- we will pass this to a deep neural network with a **WaveNet** architecture to simulate the receiver responses;\n",
    "\n",
    "- we will train this network with many example ground truth FD simulations;\n",
    "\n",
    "- we will compare the accuracy and computational performance of the trained network to FD simulation.\n",
    "\n",
    "This workflow is shown below.\n",
    "\n",
    "<img src=\"figures/workflow.png\" width=\"850\">\n",
    "\n",
    "\n",
    "## Sections\n",
    "\n",
    "There are 5 sections to complete in this notebook. This is an interactive notebook; during each section you will be asked to complete some short coding tasks and answer some questions as you go along.\n",
    "\n",
    "The sections are as follows:\n",
    "\n",
    "- [Section 1: Data loading and exploration](#Section-1:-Data-loading-and-exploration)\n",
    "\n",
    "- [Section 2: Designing a deep learning model](#Section-2:-Designing-a-deep-learning-model)\n",
    "\n",
    "- [Section 3: Training the model](#Section-3:-Training-the-model)\n",
    "\n",
    "- [Section 4: Evaluating performance](#Section-4:-Evaluating-performance)\n",
    "\n",
    "- [Section 5: Seismic inversion (optional extra)](#Section-5:-Seismic-inversion-(optional-extra))\n",
    "\n",
    "\n",
    "\n",
    "## Installation\n",
    "\n",
    "### 1. Python enviroment\n",
    "\n",
    "This notebook only requires Python libraries to run. We recommend setting up an new environment, for example\n",
    "```bash\n",
    "conda create -n workshop python=3.6  # Use Anaconda package manager\n",
    "source activate workshop\n",
    "```\n",
    "and then installing the following dependencies:\n",
    "```bash\n",
    "pip install --ignore-installed --upgrade [packageURL]# install tensorflow (get packageURL from https://www.tensorflow.org/install/pip, see tensorflow website for details)\n",
    "pip install tqdm requests\n",
    "conda install matplotlib jupyter\n",
    "```\n",
    "\n",
    "Please ensure you install **Tensorflow version 1.10** or above.\n",
    "\n",
    "Then download the source code:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/benmoseley/seismic-simulation-wavenet.git\n",
    "```\n",
    "\n",
    "Finally, check your environment is set up correctly by importing the required libraries for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import main, models, datasets, constants\n",
    "import io_utils, downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Downloading data\n",
    "\n",
    "This notebook requires access to a pre-made dataset for training and testing our deep neural network, as well as some pretrained tensorflow model files.\n",
    "\n",
    "Please use the code below to download this data.\n",
    "\n",
    "Note: the file size of the seismic dataset is **~600 Mb** and the file size of the pretrained files are **~100 Mb** - ensure you have enough disk space beforehand!\n",
    "\n",
    "Please **unzip** the pretrained model files after downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download the training data and pretrained model files (~700 Mb total)\n",
    "io_utils.get_dir(\"data/\")# create data directory\n",
    "if not os.path.isfile(\"data/layers_8ms.bin\"):# download data\n",
    "    downloader.get_url(url=\"https://benmoseley.blog/uploads/DIP/layers_8ms.bin\",\n",
    "                       file_path=\"data/layers_8ms.bin\")\n",
    "if not (os.path.isfile(\"data/pretrained.zip\") or os.path.isdir(\"data/pretrained\")):# download pretrained model files\n",
    "    downloader.get_url(url=\"https://benmoseley.blog/uploads/DIP/pretrained.zip\",\n",
    "                       file_path=\"data/pretrained.zip\")# please unzip this folder after downloading\n",
    "if os.path.getsize(\"data/layers_8ms.bin\") != 594880000: raise Exception(\"Try downloading data again, it appears corrupt.\")\n",
    "print(\"Data downloaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Data loading and exploration\n",
    "\n",
    "In this section we will explore the downloaded dataset. This dataset contains 20,000 example simulations which we will use to train and test our deep neural network.\n",
    "\n",
    "Each example simulation consists of a horizontally layered velocity model, its corresponding zero-offset reflectivity series and the pressure recorded at each receiver location. The pressure response has been simulated offline using the velocity model and 2D acoustic finite difference modelling. The reflectivity series has also been precomputed offline for you using the velocity model and  a simple 1-D depth to time conversion.\n",
    "\n",
    "> **Task 1:** use `matplotlib` to visualise some of the examples.\n",
    "\n",
    "Note:\n",
    "\n",
    "- the velocity model is sampled in depth with a spacing of 12.5 m;\n",
    "- the reflectivity model and receiver recordings are sampled in time with a sample rate of 0.008 s;\n",
    "- The receiver spacing is 200 m.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### TODO: run the following code to read the provided dataset into Python.\n",
    "# Note: data/layers_8ms.bin is a flat binary file containing all of the examples.\n",
    "# The datasets.SeismicDataset class loads examples from the binary file into numpy arrays.\n",
    "# The constants.Constants class feeds necessary constants to the SeismicDataset class.\n",
    "\n",
    "# define constants\n",
    "c = constants.Constants()\n",
    "c[\"DATA_PATH\"]=\"data/layers_8ms.bin\"# path to dataset\n",
    "c[\"N_EXAMPLES\"]=20000# number of examples in dataset\n",
    "c[\"VELOCITY_SHAPE\"]=(236, 1)# (Number of depth steps, 1)\n",
    "c[\"REFLECTIVITY_SHAPE\"]=(600, 1)# (Number of time steps, 1)\n",
    "c[\"GATHER_SHAPE\"]=(600, 11)# (Number of time steps, Number of receivers)\n",
    "\n",
    "# create a SeismicDataset object\n",
    "dataset = datasets.SeismicDataset(c)\n",
    "print(len(dataset))\n",
    "\n",
    "# get the first example from the dataset\n",
    "velocity_array, reflectivity_array, gather_array = dataset[0]\n",
    "print(type(velocity_array), velocity_array.shape)\n",
    "print(type(gather_array), gather_array.shape)\n",
    "\n",
    "### TODO: Enter you code to visualise a few of the examples here:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question 1:** what formula should be used for converting velocity models to their (zero offset) reflectivity series?\n",
    "\n",
    "Note: a constant density model was used during simulation. You can check the precomputed reflectivity series are correct by calculating you own reflectivity series and comparing them.\n",
    "\n",
    "\n",
    "> **Task 2:** plot the histograms of layer velocity values and layer thicknesses across the entire dataset.\n",
    "\n",
    "Note: the provided velocity models all start at 1500 m/s which leads to a spike in the velocity histogram at this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Enter you code here:\n",
    "# Hint: you can use plt.hist to make the histogram\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Designing a deep learning model\n",
    "\n",
    "We will now define a deep neural network which can simulate the receiver responses, given a velocity model as input.\n",
    "\n",
    "For a horizontally layered velocity model and horizontally offset receivers, each receiver response is **causally correlated** to the reflectivity series. More precisely, each pressure sample in time is at most correlated to the reflectivity values from previous times. \n",
    "\n",
    "We will model the receiver responses using a network which honours this casual relationship. Here, we will choose a **WaveNet** design, shown in the figure below. This architecture was originally designed for speech synthesis (for more info see here: https://deepmind.com/blog/wavenet-generative-model-raw-audio/).\n",
    "\n",
    "<img src=\"figures/wavenet.png\" width=\"500\">\n",
    "\n",
    "This model consists of **stacked, casually connected, exponentially dilated convolutional layers**.  The model is causal by design and the exponential dilations allow the field of view of the network to increase exponentially with the depth of the network. \n",
    "\n",
    "The input to the WaveNet is the preprocessed reflectivity series corresponding to the input velocity model and the output of the WaveNet is passed to a **final causal convolutional layer with no activation** to generate the output receiver pressure predictions. Each channel in the output tensor corresponds to a receiver prediction.\n",
    "\n",
    "\n",
    "There are a number of key hyperparameters to decide in this model, including:\n",
    "\n",
    "- number of hidden layers\n",
    "- number of hidden channels\n",
    "- activation function\n",
    "- filter length of the final convolutional layer\n",
    "\n",
    "> **Task 3:** define a WaveNet model in Tensorflow and visualise the model's graph using Tensorboard. \n",
    "\n",
    "<img src=\"figures/tensorboard_graph.png\" width=\"800\">\n",
    "\n",
    "Hint: to launch tensorboard run `tensorboard --logdir .` in the current directory, and then navigate your web browser to the address shown.\n",
    "\n",
    "If you are new to tensorboard, have a read through this guide on visualising graphs using Tensorboard: https://www.tensorflow.org/guide/graph_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Run the code below to define a WaveNet model, then visualise the graph using Tensorboard.\n",
    "### TODO: Vary the hyperparameters of the model to see how this affects the model graph.\n",
    "### TODO: Look through the source code of wavenet.py and try to understand how the WaveNet is defined.\n",
    "### the WaveNet source code is also available here: https://github.com/benmoseley/simple-wavenet.\n",
    "\n",
    "# Note:\n",
    "# The constants.Constants class is used to hold all model hyperparameters\n",
    "# The models.SeismicWavenet class is used to define a WaveNet model in tensorflow\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# define model hyperparameters\n",
    "c = constants.Constants()\n",
    "c[\"NUM_WAVE_BLOCKS\"] = 1# number of WaveNet blocks to use\n",
    "c[\"WAVE_HIDDEN_CHANNELS\"] = 256# number of hidden channels in WaveNet\n",
    "c[\"WAVE_RATES\"] = [1,2,4,8,16,32,64,128,256]# dilation rates for each convolutional layer\n",
    "c[\"WAVE_BIASES\"] = False# whether to use biases in the WaveNet\n",
    "c[\"WAVE_ACTIVATION\"] = tf.nn.relu# activation function\n",
    "c[\"CONV_FILTER_LENGTH\"] = 101# filter length of the final output convolutional layer\n",
    "\n",
    "# define model input and output tensorflow placeholders\n",
    "velocity = tf.placeholder(shape=(None, 236, 1), dtype=tf.float32, name=\"velocity\")\n",
    "reflectivity = tf.placeholder(shape=(None, 600, 1), dtype=tf.float32, name=\"reflectivity\")\n",
    "gather = tf.placeholder(shape=(None, 600, 11), dtype=tf.float32, name=\"gather\")\n",
    "input_features = {\"velocity\":velocity, \"reflectivity\": reflectivity, \"gather\": gather}\n",
    "\n",
    "# define model graph\n",
    "model = models.SeismicWavenet(c, input_features)\n",
    "model.define_graph()\n",
    "print(model.y.shape)# the output tensor of the model - check this is the right shape!\n",
    "\n",
    "# save graph to events file for tensorboard visualisation\n",
    "io_utils.get_dir(\"wavenet_graph/\")# create data directory\n",
    "io_utils.clear_dir(\"wavenet_graph/\")# careful - clears all files in this directory\n",
    "summary_writer = tf.summary.FileWriter(\"wavenet_graph/\",\n",
    "                                       filename_suffix=\".wavenet_graph\")# write events file to current directory\n",
    "with tf.Session() as sess: summary_writer.add_graph(sess.graph)\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question 2:** what does the first dimension of the output tensor (model.y) define?\n",
    "\n",
    "> **Question 3:** how does changing the number of hidden channels affect the network?\n",
    "\n",
    "> **Question 4:** why do we left-pad each input layer before carrying out a convolution?\n",
    "\n",
    "> **Question 5:** why is the final output convolutional layer important?\n",
    "\n",
    "> **Question 6:** what are the total number of trainable parameters in your model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Write some code to check Question 6 here:\n",
    "# hint: tf.trainable_variables() lists all trainable variables\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Training the model\n",
    "\n",
    "In this section we will train the WaveNet model we defined in Section 2.\n",
    "\n",
    "We will use an Adam optimiser with mini-batches of examples, and an $l_{p}$-norm loss function of the form:\n",
    "\n",
    "$$\n",
    "L = {1\\over N} \\lVert G(\\hat{Y} - Y)\\rVert_{p}^{p}~,\n",
    "$$\n",
    "\n",
    "Where $N$ is the mini-batch size, $\\hat{Y}$ are the predicted receiver responses, $Y$ are the true receiver responses from FD simulation and $G$ is a gain function of the form $G=t^{2}$, where $t$ is the sample time.\n",
    "\n",
    "We use this heuristic gain function to increase the weight of later time samples in the pressure responses which are attenuated by spherical divergence and transmission loss.\n",
    "\n",
    "We will use the first 80% of the data to train the model and withhold the last 20% for testing.\n",
    "\n",
    "> **Task 4:** define a loss function and optimiser for your model, and visualise the graph using Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Run the code below to define a loss function and optimiser.\n",
    "### Read through the model.define_loss() source code in models.py to see how\n",
    "### the loss function and the optimiser operation are defined.\n",
    "### Visualise the graph using Tensorboard.\n",
    "\n",
    "# define loss and optimiser hyperparameters\n",
    "c[\"BATCH_SIZE\"] = 20# number of examples in each min-batch\n",
    "c[\"LRATE\"] = 1e-5# learning rate for Adam\n",
    "c[\"T_GAIN\"] = 2# gain exponent\n",
    "c[\"L_NUM\"] = 2# LP loss number (1 = L1 loss, 2 = L2 loss)\n",
    "\n",
    "# define loss and optimiser in graph\n",
    "model.define_loss()\n",
    "\n",
    "# save graph to events file for tensorboard visualisation\n",
    "io_utils.get_dir(\"wavenet_graph_with_loss/\")# create data directory\n",
    "io_utils.clear_dir(\"wavenet_graph_with_loss/\")# careful - clears all files in this directory\n",
    "summary_writer = tf.summary.FileWriter(\"wavenet_graph_with_loss/\",\n",
    "                                       filename_suffix=\".wavenet_graph_with_loss\")# write events file to current directory\n",
    "with tf.Session() as sess: summary_writer.add_graph(sess.graph)\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Task 5:** (optional) train your model.\n",
    "\n",
    "**Please note: training takes ~ 5 hrs on a GPU or >1 day on a CPU. If you do not have the spare time/ computational resource please skip this step and use the pre-trained model file and tensorboard event file provided.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: run this code to train the model.\n",
    "### YOU CAN SKIP THIS STEP IF YOU DO NOT HAVE THE TIME/COMPUTATIONAL RESOURCE\n",
    "\n",
    "### This code uses the main.Trainer class to train the model, which periodically saves model\n",
    "### files and tensorboard summaries to the results/ folder.\n",
    "### The main.Trainer class also automatically splits the dataset into 80:20 training/test data\n",
    "\n",
    "### TODO: have a look through the constants.py source code to see some of the other\n",
    "### constants you can set. For example, when running on a GPU you can \n",
    "### set the cuda device with c.DEVICE.\n",
    "\n",
    "# define some training parameters\n",
    "c[\"MODEL_RUN\"] = \"mytrainedmodel\"# name of the training run\n",
    "c[\"N_STEPS\"] = 100000# number of training steps\n",
    "c[\"DEVICE\"] = 0# cuda device number\n",
    "\n",
    "# train the model\n",
    "tf.reset_default_graph()\n",
    "run = main.Trainer(c)\n",
    "#run.train()# uncomment to start training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Task 6:** view the training progress in Tensorboard.\n",
    "\n",
    "If you haven't trained your own model, have a look at the pre-trained model tensorboard event file in the `data/pretrained/forward/` folder provided.\n",
    "\n",
    "<img src=\"figures/tensorboard_training.png\" width=\"800\">\n",
    "\n",
    "Note `main.Trainer` also outputs example predictions in the \"IMAGES\" tab as training progresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Evaluating performance\n",
    "\n",
    "Finally, we will plot some of the simulations from our trained model and compare them to test examples in our dataset.\n",
    "\n",
    "Use the code below to load one of your saved models from file. If you haven't trained your own model, select the pre-trained model file in `data/pretrained/forward/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: run the code below to load a saved model from file.\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "### TODO: IF YOU TRAINED YOUR OWN MODEL: SPECIFY YOUR SAVED MODEL AND ITS CORRESPONDING CONSTANTS FILE HERE\n",
    "MODEL_LOAD_PATH = \"results/models/mytrainedmodel/model.ckpt-XX\"\n",
    "CONSTANTS_LOAD_PATH = \"results/summaries/mytrainedmodel/constants_mytrainedmodel.pickle\"\n",
    "###\n",
    "### OTHERWISE, LOAD THE PRE-TRAINED MODEL BY USING THE FOLLOWING\n",
    "MODEL_LOAD_PATH = \"data/pretrained/forward/model.ckpt-500000\"\n",
    "CONSTANTS_LOAD_PATH = \"data/pretrained/forward/constants_forward.pickle\"\n",
    "###\n",
    "\n",
    "# load the model's saved constants object\n",
    "c_dict = constants.load_constants_dict(CONSTANTS_LOAD_PATH)\n",
    "c = constants.Constants(**c_dict)\n",
    "\n",
    "# define model input and output tensorflow placeholders\n",
    "velocity = tf.placeholder(shape=(None, 236, 1), dtype=tf.float32, name=\"velocity\")\n",
    "reflectivity = tf.placeholder(shape=(None, 600, 1), dtype=tf.float32, name=\"reflectivity\")\n",
    "gather = tf.placeholder(shape=(None, 600, 11), dtype=tf.float32, name=\"gather\")\n",
    "input_features = {\"velocity\":velocity, \"reflectivity\": reflectivity, \"gather\": gather}\n",
    "\n",
    "# define and load model\n",
    "model = models.SeismicWavenet(c, input_features)\n",
    "model.define_graph()\n",
    "model.define_loss()\n",
    "saver = tf.train.Saver()# for loading model\n",
    "sess = tf.Session()\n",
    "saver.restore(sess, MODEL_LOAD_PATH)# restore weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Task 7:** Plot the model predictions for some of the unseen velocity models in the test dataset and compare them to their ground truth FD simulations.\n",
    "\n",
    "> **Task 8:** Measure the time taken to generate 100 predictions.\n",
    "\n",
    "> **Question 7:** How do these results compare to FD modelling? What are the differences?\n",
    "\n",
    "Note: each FD simulation typically takes of the order of 1 s to run on a single CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: to run some predictions, use the following code:\n",
    "\n",
    "c[\"DATA_PATH\"]=\"data/layers_8ms.bin\"# ensure data path set correctly in loaded constants file\n",
    "\n",
    "# grab some test data\n",
    "dataset = datasets.SeismicDataset(c)\n",
    "velocity_array, reflectivity_array, gather_array = dataset[16000:16004]# the first four examples in the test dataset\n",
    "print(reflectivity_array.shape)# (Note slicing a SeismicDataset object returns a batch of examples)\n",
    "\n",
    "# run a model prediction\n",
    "gather_prediction_array = sess.run(model.y, feed_dict={reflectivity: reflectivity_array})\n",
    "print(gather_prediction_array.shape)\n",
    "\n",
    "### TODO: Enter your code to visualise the model predictions here:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### TODO: Enter your code to time the prediction step here:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Extension (optional): you could try feeding the model velocity models outside of its training data\n",
    "### distribution e.g. ones with smoothly varying velocity values (instead of layers) - and evaluate \n",
    "### how stable the model predictions appear in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Seismic inversion (optional extra)\n",
    "\n",
    "We can also use the same WaveNet architecture to carry out **seismic inversion** of this datset: namely, given a set of receiver recordings, can we invert for the underlying velocity model?\n",
    "\n",
    "For this model, we can simply **reverse the inputs and outputs** of our WaveNet model and retrain the model!\n",
    "\n",
    "The provided `models.SeismicWavenet` class is expressive enough to handle this; whether the model carries out forward or inverse modelling can be controlled by its `SeismicWavenet(inverse=True)` input flag. When wrapping `SeismicWavenet` with the `main.Trainer` class, this flag can be set via the `constants.Constants` class, ie, setting `c[\"inverse\"]=True`.\n",
    "\n",
    "> **Optional Task 1**: re-use the code above to train a model which carries out seismic inversion. \n",
    "\n",
    "> **Optional Task 2:** Visualise the predictions of your model by adapting your code from Task 7. \n",
    "\n",
    "If training is too expensive, you can use the pretrained model file and events file in `data/pretrained/inverse/` provided to help you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# TODO: Enter your code to train/ visualise the inverse modelling here:\n",
    "# hint: the processing_utils.get_velocity_trace() function can convert a predicted\n",
    "# reflectivity series to its corresponding velocity trace\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
